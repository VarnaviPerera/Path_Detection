{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXqwEml095cS",
        "outputId": "0c3e82c2-106b-4991-907d-099394a10177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ZLNBRxAIyp",
        "outputId": "40468191-78a5-41f4-a21f-cb35695d0584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TeaBot Research Dataset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/TeaBot Research Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWDh14NaAYHC"
      },
      "outputs": [],
      "source": [
        "input_folder ='/content/drive/MyDrive/TeaBot Research Dataset/model/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APnHJ10CAo3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab20a381-74e3-456c-f892-9fc1f5e46818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating training images...\n",
            "['/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/111.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/105_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/101.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/108.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/104_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/103.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/10.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/104.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/106.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/116_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/112.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/115_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/114.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/102_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/100.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/103_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/115.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/102.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/114_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/10_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/113.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/107.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/106_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/11.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/11_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/112_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/108_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/101_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/105.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/110_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/107_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/109_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/100_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/111_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/110.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/109.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/116.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/113_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/129_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/137.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/141_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/147_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/125_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/135_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/117.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/132_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/132.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/129.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/127_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/134.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/124_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/143_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/133.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/131_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/147.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/12_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/125.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/121.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/13.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/136.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/131.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/149.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/143.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/141.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/145_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/119.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/135.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/138.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/149_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/140.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/118.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/139.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/148_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/117_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/127.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/148.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/130_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/14_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/133_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/12.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/130.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/122_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/138_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/144_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/118_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/119_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/146_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/123.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/14.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/146.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/142.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/128.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/136_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/142_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/126_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/128_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/145.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/139_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/121_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/140_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/126.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/144.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/123_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/120.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/13_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/120_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/137_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/122.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/124.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/134_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/180.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/175_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/166_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/177_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/173.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/166.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/18_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/158.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/182.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/156.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/183_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/169.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/157.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/17.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/178.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/154.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/156_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/170.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/163.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/173_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/154_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/167.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/179.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/169_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/16.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/150_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/167_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/177.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/179_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/162.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/175.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/172_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/16_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/152_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/160_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/161_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/15_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/18.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/180_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/172.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/165_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/174.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/181_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/174_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/151.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/153.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/15.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/160.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/171.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/170_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/155_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/157_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/168_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/182_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/159_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/183.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/163_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/168.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/159.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/161.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/150.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/181.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/17_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/176_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/158_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/171_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/176.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/165.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/184_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/155.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/151_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/153_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/152.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/164_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/162_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/178_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/164.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/184.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/191.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/20.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/192.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/198.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/190.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/189.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/196.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/188_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/188.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/189_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/187_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/185.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/192_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/186_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/190_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/19_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/20_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/191_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/186.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/195.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/194_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/194.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/195_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/185_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/196_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/197.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/19.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/193.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/187.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/193_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/21_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/21.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/22_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/22.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/223.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/224.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/225.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/226.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/227.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/23.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/228.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/229.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/23_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/230.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/232.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/231.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/233.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/234.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/235.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/236.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/237.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/239.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/24.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/238.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/24_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/241.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/240.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/242.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/243.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/244.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/245.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/247.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/246.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/248.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/250.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/251.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/25.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/25_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/249.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/254.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/253.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/252.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/255.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/256.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/257.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/260.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/258.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/259.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/261.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/26_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/26.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/263.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/265.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/264.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/262.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/266.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/267.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/268.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/271.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/270.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/27.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/27_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/269.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/272.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/275.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/277.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/276.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/278.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/28.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/28_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/279.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/280.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/282.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/281.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/283.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/284.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/285.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/287.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/288.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/289.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/29.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/290.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/29_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/292.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/291.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/293.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/294.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/295.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/297.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/296.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/299.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/298.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/300.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/30.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/30_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/301.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/302.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/303.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/305.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/304.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/307.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/306.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/31.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/31_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/32_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/32.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/44_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/37_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/47.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/46_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/41_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/36_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/38.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/41.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/42.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/34_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/38_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/43.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/48_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/40_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/40.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/36.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/35_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/43_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/47_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/45_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/39_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/33.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/35.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/39.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/42_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/46.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/33_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/48.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/44.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/37.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/34.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/49.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/45.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/49_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/61.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/53.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/52_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/54.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/66.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/63_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/62.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/55_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/50.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/60_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/57.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/55.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/51.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/71_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/70_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/70.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/67_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/57_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/65_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/69_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/56.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/51_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/50_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/53_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/62_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/71.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/59.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/63.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/61_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/67.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/58.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/65.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/58_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/56_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/64_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/68.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/52.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/68_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/54_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/60.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/64.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/69.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/66_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/59_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/83.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/76_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/74_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/80_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/88.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/86_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/90_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/72.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/88_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/75_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/79.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/90.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/78.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/89.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/89_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/84_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/82_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/85.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/81.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/81_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/85_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/76.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/84.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/77_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/9_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/72_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/73.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/77.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/87.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/9.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/78_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/79_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/82.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/75.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/87_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/86.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/74.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/73_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/80.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/83_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/96_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/94_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/93.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/97_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/92_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/93_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/92.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/97.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/91_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/99_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/94.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/96.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/91.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/99.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/98.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/98_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/95_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/95.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/203.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/273.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/274.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/286.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/199.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/200.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/201.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/202.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/204.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/205.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/206.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/207.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/208.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/209.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/210.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/211.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/212.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/213.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/214.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/215.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/216.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/217.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/218.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/219.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/220.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/221.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/222.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/1_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/1.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/2_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/2.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/3_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/3.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/4_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/4.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/5_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/5.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/6.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/7_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/7.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/8_copy.jpg', '/content/drive/MyDrive/TeaBot Research Dataset/model/train/image/8.jpg']\n",
            "Done: 0/502 images\n",
            "Done: 100/502 images\n",
            "Done: 200/502 images\n",
            "Done: 300/502 images\n",
            "Done: 400/502 images\n",
            "Done: 500/502 images\n",
            "loading done\n",
            "Saving to .npy files done.\n",
            "Creating testall images...\n",
            "loading done\n",
            "Saving to .npy files done.\n",
            "Creating test images...\n",
            "loading done\n",
            "Saving to imgs_test.npy files done.\n",
            "Creating validation images...\n",
            "loading done\n",
            "Saving to .npy files done.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "\n",
        "from tensorflow.keras.utils import img_to_array, load_img\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "#NAME = \"N175SB\"\n",
        "NAME=1\n",
        "\n",
        "class dataProcess(object):\n",
        "    def __init__(self, out_rows, out_cols, data_path=\"/content/drive/MyDrive/TeaBot Research Dataset/model/train/image\",\n",
        "                 label_path=\"/content/drive/MyDrive/TeaBot Research Dataset/model/train/label\", test_path=\"/content/drive/MyDrive/TeaBot Research Dataset/model/test/image\",\n",
        "                 testlabel_path=\"/content/drive/MyDrive/TeaBot Research Dataset/model/test/label\", val_path=\"/content/drive/MyDrive/TeaBot Research Dataset/model/val/image\",\n",
        "                 vallabel_path=\"/content/drive/MyDrive/TeaBot Research Dataset/model/val/label\", npy_path=\"/content/drive/MyDrive/TeaBot Research Dataset/npydata\",\n",
        "                 img_type=\"jpg\"):\n",
        "      #\n",
        "      #\n",
        "      #\n",
        "      #changed npy_path=\"/content/drive/MyDrive/TeaBot Research Dataset/npydata\" to npy_path=\"/content/drive/MyDrive/TeaBot Research Dataset/model\"\n",
        "      #CHANGED FROM  /content/drive/MyDrive/TeaBot Research Dataset/model/train/\"+NAME+\"/image\" TO /content/drive/MyDrive/TeaBot Research Dataset/model/train/image\"\n",
        "      #IN LABEL\n",
        "      #\n",
        "      #\n",
        "      #\n",
        "        self.out_rows = out_rows\n",
        "        self.out_cols = out_cols\n",
        "        self.data_path = data_path\n",
        "        self.label_path = label_path\n",
        "        self.img_type = img_type\n",
        "        self.test_path = test_path\n",
        "        self.testlabel_path = testlabel_path\n",
        "        self.val_path = val_path\n",
        "        self.vallabel_path = vallabel_path\n",
        "        self.npy_path = npy_path\n",
        "\n",
        "    def create_train_data(self):\n",
        "        i = 0\n",
        "        print('Creating training images...')\n",
        "        imgs = glob.glob(self.data_path+\"/*.\"+self.img_type)\n",
        "        print(imgs)\n",
        "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
        "        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "\n",
        "        for x in range(len(imgs)):\n",
        "            imgpath = imgs[x]\n",
        "            pic_name = imgpath.split('/')[-1]\n",
        "            labelpath = self.label_path + '/' + pic_name\n",
        "            img = load_img(imgpath, color_mode='rgb', target_size=[512, 512])\n",
        "            label = load_img(labelpath, color_mode='grayscale', target_size=[512, 512])\n",
        "            img = img_to_array(img)\n",
        "            label = img_to_array(label)\n",
        "            imgdatas[i] = img\n",
        "            imglabels[i] = label\n",
        "            if i % 100 == 0:\n",
        "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
        "            i += 1\n",
        "\n",
        "        print('loading done')\n",
        "        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n",
        "        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def create_test_all(self):\n",
        "    #     i = 0\n",
        "    #     print('Creating testall images...')\n",
        "    #     imgs = glob.glob(self.test_path+\"/*.\"+self.img_type)\n",
        "    #     depths = glob.glob(self.depth_path+\"/*.\"+self.img_type)\n",
        "    #     imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 4), dtype=np.uint8)\n",
        "    #     imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "\n",
        "    #     for x in range(len(imgs)):\n",
        "    #         imgpath = imgs[x]\n",
        "    #         pic_name = imgpath.split('/')[-1]\n",
        "    #         labelpath = self.testlabel_path + '/' + pic_name\n",
        "    #         #depthpath = self.testdepth_path + '/' + pic_name\n",
        "    #         img = load_img(imgpath, color_mode='rgb', target_size=[512, 512])\n",
        "    #         depth = load_img(depthpath, color_mode='grayscale', target_size=[512, 512])\n",
        "    #         label = load_img(labelpath, color_mode='grayscale', target_size=[512, 512])\n",
        "    #         img = img_to_array(img)\n",
        "    #         #depth = img_to_array(depth)\n",
        "    #         img = np.dstack((img, depth))#rgbd array\n",
        "    #         label = img_to_array(label)\n",
        "    #         imgdatas[i] = img\n",
        "    #         imglabels[i] = label\n",
        "    #         if i % 100 == 0:\n",
        "    #             print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
        "    #         i += 1\n",
        "\n",
        "    #     print('loading done')\n",
        "    #     np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
        "    #     np.save(self.npy_path + '/imgs_mask_test.npy', imglabels)\n",
        "    #     print('Saving to .npy files done.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def create_test_all(self):\n",
        "        i = 0\n",
        "        print('Creating testall images...')\n",
        "        imgs = glob.glob(self.test_path+\"/*.\"+self.img_type)\n",
        "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
        "        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "\n",
        "        for x in range(len(imgs)):\n",
        "            imgpath = imgs[x]\n",
        "            pic_name = imgpath.split('/')[-1]\n",
        "            labelpath = self.testlabel_path + '/' + pic_name\n",
        "            img = load_img(imgpath, color_mode='rgb', target_size=[512, 512])\n",
        "            label = load_img(labelpath, color_mode='grayscale', target_size=[512, 512])\n",
        "            img = img_to_array(img)\n",
        "            label = img_to_array(label)\n",
        "            imgdatas[i] = img\n",
        "            imglabels[i] = label\n",
        "            if i % 100 == 0:\n",
        "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
        "            i += 1\n",
        "\n",
        "        print('loading done')\n",
        "        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
        "        np.save(self.npy_path + '/imgs_mask_test.npy', imglabels)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "    def create_val_data(self):\n",
        "        i = 0\n",
        "        print('Creating validation images...')\n",
        "        imgs = glob.glob(self.val_path+\"/*.\"+self.img_type)\n",
        "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
        "        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "\n",
        "        for x in range(len(imgs)):\n",
        "            imgpath = imgs[x]\n",
        "            pic_name = imgpath.split('/')[-1]\n",
        "            labelpath = self.vallabel_path + '/' + pic_name\n",
        "            img = load_img(imgpath, color_mode='rgb', target_size=[512, 512])\n",
        "            label = load_img(labelpath, color_mode='grayscale', target_size=[512, 512])\n",
        "            img = img_to_array(img)\n",
        "            label = img_to_array(label)\n",
        "            imgdatas[i] = img\n",
        "            imglabels[i] = label\n",
        "            if i % 100 == 0:\n",
        "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
        "            i += 1\n",
        "\n",
        "        print('loading done')\n",
        "        np.save(self.npy_path + '/imgs_val.npy', imgdatas)\n",
        "        np.save(self.npy_path + '/imgs_mask_val.npy', imglabels)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "\n",
        "    def create_test_data(self):\n",
        "        i = 0\n",
        "        print('Creating test images...')\n",
        "        imgs = glob.glob(self.test_path + \"/*.\" + self.img_type)\n",
        "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
        "        testpathlist = []\n",
        "\n",
        "        for imgname in imgs:\n",
        "            testpath = imgname\n",
        "            testpathlist.append(testpath)\n",
        "            img = load_img(testpath, color_mode='rgb', target_size=[512, 512])\n",
        "            img = img_to_array(img)\n",
        "            imgdatas[i] = img\n",
        "            i += 1\n",
        "\n",
        "        txtname = '/content/drive/MyDrive/TeaBot Research Dataset/results/pic.txt'\n",
        "        with open(txtname, 'w') as f:\n",
        "            for i in range(len(testpathlist)):\n",
        "                f.writelines(testpathlist[i] + '\\n')\n",
        "        print('loading done')\n",
        "        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
        "        print('Saving to imgs_test.npy files done.')\n",
        "\n",
        "    def load_train_data(self):\n",
        "        print('load train images...')\n",
        "        imgs_train = np.load(self.npy_path + \"/imgs_train.npy\")\n",
        "        imgs_mask_train = np.load(self.npy_path + \"/imgs_mask_train.npy\")\n",
        "        imgs_train = imgs_train.astype('float32')\n",
        "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "        imgs_train /= 255\n",
        "        imgs_mask_train /= 255\n",
        "        imgs_mask_train[imgs_mask_train > 0.5] = 1  # 白\n",
        "        imgs_mask_train[imgs_mask_train <= 0.5] = 0  # 黑\n",
        "        return imgs_train, imgs_mask_train\n",
        "\n",
        "    def load_test_data(self):\n",
        "        print('-' * 30)\n",
        "        print('load test images...')\n",
        "        print('-' * 30)\n",
        "        imgs_test = np.load(self.npy_path + \"/imgs_test.npy\")\n",
        "        imgs_test = imgs_test.astype('float32')\n",
        "        imgs_test /= 255\n",
        "        return imgs_test\n",
        "\n",
        "    def load_test_labels(self):\n",
        "        print('-' * 30)\n",
        "        print('load test label images...')\n",
        "        print('-' * 30)\n",
        "        imgs_testlabels = np.load(self.npy_path + \"/imgs_mask_test.npy\")\n",
        "        imgs_testlabels = imgs_testlabels.astype('float32')\n",
        "        imgs_testlabels /= 255\n",
        "        return imgs_testlabels\n",
        "\n",
        "    def load_val_data(self):\n",
        "        print('load train images...')\n",
        "        imgs_val = np.load(self.npy_path + \"/imgs_val.npy\")\n",
        "        imgs_mask_val = np.load(self.npy_path + \"/imgs_mask_val.npy\")\n",
        "        imgs_val = imgs_val.astype('float32')\n",
        "        imgs_mask_val = imgs_mask_val.astype('float32')\n",
        "        imgs_val /= 255\n",
        "        imgs_mask_val /= 255\n",
        "        imgs_mask_val[imgs_mask_val > 0.5] = 1\n",
        "        imgs_mask_val[imgs_mask_val <= 0.5] = 0\n",
        "        return imgs_val, imgs_mask_val\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mydata = dataProcess(512, 512)\n",
        "    mydata.create_train_data()\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #REMOVE COMMENT\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    mydata.create_test_all()\n",
        "    mydata.create_test_data()\n",
        "    mydata.create_val_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFPLqkx2JWGm"
      },
      "outputs": [],
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "%load_ext tensorboard\n",
        "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/TeaBot Research Dataset/model/') #to import data.py file\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import cv2\n",
        "#\n",
        "#\n",
        "#\n",
        "# from model import *\n",
        "#import tensorflow.experimental.numpy as np\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "from collections import defaultdict\n",
        "import math\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPhUHqZJy1s"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0EBoGiXF5O3",
        "outputId": "986e8473-5a1b-4d46-cb7a-74b911c26309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1 shape: (None, 512, 512, 64)\n",
            "conv1 shape: (None, 512, 512, 64)\n",
            "pool1 shape: (None, 256, 256, 64)\n",
            "conv2 shape: (None, 256, 256, 128)\n",
            "conv2 shape: (None, 256, 256, 128)\n",
            "pool2 shape: (None, 128, 128, 128)\n",
            "conv3 shape: (None, 128, 128, 256)\n",
            "conv3 shape: (None, 128, 128, 256)\n",
            "pool3 shape: (None, 64, 64, 256)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_10/Relu:0', description=\"created by layer 'conv2d_10'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 1024), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_11/Relu:0', description=\"created by layer 'conv2d_11'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_12/Relu:0', description=\"created by layer 'conv2d_12'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_13/Relu:0', description=\"created by layer 'conv2d_13'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 512), dtype=tf.float32, name=None), name='concatenate_1/concat:0', description=\"created by layer 'concatenate_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_14/Relu:0', description=\"created by layer 'conv2d_14'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_15/Relu:0', description=\"created by layer 'conv2d_15'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='conv2d_19/Relu:0', description=\"created by layer 'conv2d_19'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 128), dtype=tf.float32, name=None), name='concatenate_3/concat:0', description=\"created by layer 'concatenate_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='conv2d_20/Relu:0', description=\"created by layer 'conv2d_20'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='conv2d_21/Relu:0', description=\"created by layer 'conv2d_21'\")\n",
            "conv9 shape: (None, 512, 512, 2)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None), name='conv2d_23/Sigmoid:0', description=\"created by layer 'conv2d_23'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['conv2d_2[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['conv2d_3[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['conv2d_4[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64, 64, 512)  0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 1024  9438208     ['conv2d_8[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32, 32, 1024  0           ['conv2d_9[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 64, 64, 1024  0           ['dropout_1[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 512)  2097664     ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['dropout[0][0]',                \n",
            "                                )                                 'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 512)  2359808     ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 51  0          ['conv2d_12[0][0]']              \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 128, 25  524544      ['up_sampling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_5[0][0]',               \n",
            "                                2)                                'conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 25  590080      ['conv2d_14[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 25  0          ['conv2d_15[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 12  131200      ['up_sampling2d_2[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_3[0][0]',               \n",
            "                                6)                                'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 12  147584      ['conv2d_17[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 12  0          ['conv2d_18[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 512, 512, 64  32832       ['up_sampling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_1[0][0]',               \n",
            "                                8)                                'conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 512, 512, 64  36928       ['conv2d_20[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 512, 512, 2)  1154        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 512, 512, 1)  3           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,032,837\n",
            "Trainable params: 31,032,837\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "loading data\n",
            "load train images...\n",
            "------------------------------\n",
            "load test images...\n",
            "------------------------------\n",
            "------------------------------\n",
            "load test label images...\n",
            "------------------------------\n",
            "load train images...\n",
            "loading data done\n",
            "conv1 shape: (None, 512, 512, 64)\n",
            "conv1 shape: (None, 512, 512, 64)\n",
            "pool1 shape: (None, 256, 256, 64)\n",
            "conv2 shape: (None, 256, 256, 128)\n",
            "conv2 shape: (None, 256, 256, 128)\n",
            "pool2 shape: (None, 128, 128, 128)\n",
            "conv3 shape: (None, 128, 128, 256)\n",
            "conv3 shape: (None, 128, 128, 256)\n",
            "pool3 shape: (None, 64, 64, 256)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_34/Relu:0', description=\"created by layer 'conv2d_34'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 1024), dtype=tf.float32, name=None), name='concatenate_4/concat:0', description=\"created by layer 'concatenate_4'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_35/Relu:0', description=\"created by layer 'conv2d_35'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_36/Relu:0', description=\"created by layer 'conv2d_36'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_37/Relu:0', description=\"created by layer 'conv2d_37'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 512), dtype=tf.float32, name=None), name='concatenate_5/concat:0', description=\"created by layer 'concatenate_5'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_38/Relu:0', description=\"created by layer 'conv2d_38'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_39/Relu:0', description=\"created by layer 'conv2d_39'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='conv2d_43/Relu:0', description=\"created by layer 'conv2d_43'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 128), dtype=tf.float32, name=None), name='concatenate_7/concat:0', description=\"created by layer 'concatenate_7'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='conv2d_44/Relu:0', description=\"created by layer 'conv2d_44'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='conv2d_45/Relu:0', description=\"created by layer 'conv2d_45'\")\n",
            "conv9 shape: (None, 512, 512, 2)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None), name='conv2d_47/Sigmoid:0', description=\"created by layer 'conv2d_47'\")\n",
            "got unet\n",
            "Fitting model...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f06980c27a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f06980c27a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401/401 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.7930 - iou: 0.2110\n",
            "Epoch 1: iou improved from -inf to 0.21095, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "401/401 [==============================] - 191s 413ms/step - loss: 0.4153 - accuracy: 0.7930 - iou: 0.2110 - val_loss: 0.5148 - val_accuracy: 0.7368 - val_iou: 0.2223\n",
            "Epoch 2/5\n",
            "401/401 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8107 - iou: 0.2425\n",
            "Epoch 2: iou improved from 0.21095 to 0.24253, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "401/401 [==============================] - 167s 416ms/step - loss: 0.3240 - accuracy: 0.8107 - iou: 0.2425 - val_loss: 0.4405 - val_accuracy: 0.8214 - val_iou: 0.2706\n",
            "Epoch 3/5\n",
            "401/401 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.8480 - iou: 0.2458\n",
            "Epoch 3: iou improved from 0.24253 to 0.24576, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "401/401 [==============================] - 178s 443ms/step - loss: 0.3120 - accuracy: 0.8480 - iou: 0.2458 - val_loss: 0.4520 - val_accuracy: 0.8254 - val_iou: 0.2694\n",
            "Epoch 4/5\n",
            "401/401 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.8508 - iou: 0.2476\n",
            "Epoch 4: iou improved from 0.24576 to 0.24762, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "401/401 [==============================] - 178s 445ms/step - loss: 0.3079 - accuracy: 0.8508 - iou: 0.2476 - val_loss: 0.4248 - val_accuracy: 0.8266 - val_iou: 0.2674\n",
            "Epoch 5/5\n",
            "401/401 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.8524 - iou: 0.2488\n",
            "Epoch 5: iou improved from 0.24762 to 0.24877, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "401/401 [==============================] - 167s 418ms/step - loss: 0.3041 - accuracy: 0.8524 - iou: 0.2488 - val_loss: 0.4327 - val_accuracy: 0.8266 - val_iou: 0.2743\n",
            "Epoch 1/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8491 - iou: 0.2882\n",
            "Epoch 1: iou improved from 0.24877 to 0.28823, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 207s 761ms/step - loss: 0.3225 - accuracy: 0.8491 - iou: 0.2882\n",
            "Epoch 2/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.8505 - iou: 0.2917\n",
            "Epoch 2: iou improved from 0.28823 to 0.29171, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 189s 753ms/step - loss: 0.3190 - accuracy: 0.8505 - iou: 0.2917\n",
            "Epoch 3/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8509 - iou: 0.2976\n",
            "Epoch 3: iou improved from 0.29171 to 0.29757, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 201s 802ms/step - loss: 0.3177 - accuracy: 0.8509 - iou: 0.2976\n",
            "Epoch 4/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.8538 - iou: 0.2991\n",
            "Epoch 4: iou improved from 0.29757 to 0.29913, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 211s 841ms/step - loss: 0.3136 - accuracy: 0.8538 - iou: 0.2991\n",
            "Epoch 5/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.3071 - accuracy: 0.8542 - iou: 0.3237\n",
            "Epoch 5: iou improved from 0.29913 to 0.32374, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 210s 838ms/step - loss: 0.3071 - accuracy: 0.8542 - iou: 0.3237\n",
            "Epoch 6/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8574 - iou: 0.3622\n",
            "Epoch 6: iou improved from 0.32374 to 0.36222, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 197s 784ms/step - loss: 0.2946 - accuracy: 0.8574 - iou: 0.3622\n",
            "Epoch 7/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.2886 - accuracy: 0.8602 - iou: 0.3697\n",
            "Epoch 7: iou improved from 0.36222 to 0.36971, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 202s 805ms/step - loss: 0.2886 - accuracy: 0.8602 - iou: 0.3697\n",
            "Epoch 8/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.8640 - iou: 0.3796\n",
            "Epoch 8: iou improved from 0.36971 to 0.37957, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 205s 819ms/step - loss: 0.2821 - accuracy: 0.8640 - iou: 0.3796\n",
            "Epoch 9/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.8657 - iou: 0.3858\n",
            "Epoch 9: iou improved from 0.37957 to 0.38584, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 206s 820ms/step - loss: 0.2782 - accuracy: 0.8657 - iou: 0.3858\n",
            "Epoch 10/10\n",
            "251/251 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.8684 - iou: 0.3934\n",
            "Epoch 10: iou improved from 0.38584 to 0.39345, saving model to /content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5\n",
            "251/251 [==============================] - 205s 818ms/step - loss: 0.2726 - accuracy: 0.8684 - iou: 0.3934\n"
          ]
        }
      ],
      "source": [
        "\n",
        "NAME = \"N175SB\"\n",
        "logdir = '/content/drive/MyDrive/TeaBot Research Dataset/logs/{}'.format(NAME)\n",
        "tensorboard = TensorBoard(logdir)\n",
        "\n",
        "class myUnet(object):\n",
        "    def __init__(self, img_rows=512, img_cols=512):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.eps1 = 4\n",
        "        self.eps2 = 3\n",
        "        self.htres = 100\n",
        "\n",
        "    def load_data(self):\n",
        "      #undo Coments\n",
        "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
        "        imgs_train, imgs_mask_train = mydata.load_train_data()\n",
        "        imgs_test = mydata.load_test_data()\n",
        "        imgs_mask_test = mydata.load_test_labels()\n",
        "        imgs_val, imgs_mask_val = mydata.load_val_data()\n",
        "        return imgs_train, imgs_mask_train, imgs_test, imgs_mask_test, imgs_val, imgs_mask_val\n",
        "\n",
        "    def tensor_to_image(self, tensor):\n",
        "        tensor = tensor*255\n",
        "        tensor = np.array(tensor, dtype=np.uint8)\n",
        "        if np.ndim(tensor)>3:\n",
        "            assert tensor.shape[0] == 1\n",
        "            tensor = tensor[0]\n",
        "        return PIL.Image.fromarray(tensor)\n",
        "\n",
        "    def iou(self, y_true, y_pred):\n",
        "        y_true = tf.reshape(y_true, [-1])\n",
        "        y_pred = tf.reshape(y_pred, [-1])\n",
        "        intersection = tf.reduce_sum(tf.cast(y_true, tf.float32) * tf.cast(y_pred, tf.float32))\n",
        "        score = (intersection + 1.) / (tf.reduce_sum(tf.cast(y_true, tf.float32)) + tf.reduce_sum(tf.cast(y_pred, tf.float32)) - intersection + 1.)\n",
        "        return score\n",
        "\n",
        "    def mylossiou(self, y_true, y_pred):\n",
        "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        bcloss = bce(y_true, y_pred)\n",
        "        y_true = tf.reshape(y_true, [-1])\n",
        "        y_pred = tf.reshape(y_pred, [-1])\n",
        "        intersection = tf.reduce_sum(tf.cast(y_true, tf.float32) * tf.cast(y_pred, tf.float32))\n",
        "        score = (intersection + 1.) / (tf.reduce_sum(tf.cast(y_true, tf.float32)) + tf.reduce_sum(tf.cast(y_pred, tf.float32)) - intersection + 1.)\n",
        "        iouloss = 1-score\n",
        "        ret = 0.9*bcloss + 0.1*iouloss\n",
        "        #y_p = K.print_tensor(ret.get_shape().as_list(), message='   ret = ')\n",
        "        return ret\n",
        "\n",
        "    def myloss(self, y_true, y_pred):\n",
        "        loss=tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, 5.)\n",
        "        return loss\n",
        "\n",
        "    def weightedLoss(self, originalLossFunc, weightsList):\n",
        "        def lossFunc(true, pred):\n",
        "\n",
        "            axis = -1 #if channels last\n",
        "            #axis=  1 #if channels first\n",
        "\n",
        "\n",
        "            #argmax returns the index of the element with the greatest value\n",
        "            #done in the class axis, it returns the class index\n",
        "            classSelectors = K.argmax(true, axis=axis)\n",
        "                #if your loss is sparse, use only true as classSelectors\n",
        "\n",
        "            #considering weights are ordered by class, for each class\n",
        "            #true(1) if the class index is equal to the weight index\n",
        "            classSelectors = [K.equal(i, classSelectors) for i in range(len(weightsList))]\n",
        "\n",
        "            #casting boolean to float for calculations\n",
        "            #each tensor in the list contains 1 where ground true class is equal to its index\n",
        "            #if you sum all these, you will get a tensor full of ones.\n",
        "            classSelectors = [K.cast(x, K.floatx()) for x in classSelectors]\n",
        "\n",
        "            #for each of the selections above, multiply their respective weight\n",
        "            weights = [sel * w for sel,w in zip(classSelectors, weightsList)]\n",
        "\n",
        "            #sums all the selections\n",
        "            #result is a tensor with the respective weight for each element in predictions\n",
        "            weightMultiplier = weights[0]\n",
        "            for i in range(1, len(weights)):\n",
        "                weightMultiplier = weightMultiplier + weights[i]\n",
        "\n",
        "\n",
        "            #make sure your originalLossFunc only collapses the class axis\n",
        "            #you need the other axes intact to multiply the weights tensor\n",
        "            loss = originalLossFunc(true,pred)\n",
        "            loss = loss * weightMultiplier\n",
        "\n",
        "            return loss\n",
        "        return lossFunc\n",
        "\n",
        "    #@tf.autograph.experimental.do_not_convert\n",
        "    def loss_angle(self, y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "        img = y_true.numpy()\n",
        "        lbl = y_pred.numpy()\n",
        "        img = np.reshape(img, (512,512,1))\n",
        "        lbl = np.reshape(lbl, (512,512,1))\n",
        "        img = img*255\n",
        "        lbl = lbl*255\n",
        "        #y_t = K.print_tensor(img, message='y_true = ')\n",
        "        #y_p = K.print_tensor(lbl, message='y_pred = ')\n",
        "        #img = tf.keras.preprocessing.image.array_to_img(img)\n",
        "        #lbl = tf.keras.preprocessing.image.array_to_img(lbl)\n",
        "        #img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "        #lbl=cv2.cvtColor(lbl,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        #ret,img = cv2.threshold(img, 127, 255, 0)\n",
        "        ret,lbl = cv2.threshold(lbl, 127, 255, 0)\n",
        "        #y_p = K.print_tensor(lbl, message='y_pred2 = ')\n",
        "\n",
        "        skel1 = np.zeros(img.shape, np.float32)\n",
        "        skel2 = np.zeros(lbl.shape, np.float32)\n",
        "\n",
        "        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
        "\n",
        "        while True:\n",
        "            openImg = cv2.morphologyEx(img, cv2.MORPH_OPEN, element)\n",
        "            temp = cv2.subtract(img, openImg)\n",
        "            eroded = cv2.erode(img, element)\n",
        "            skel1 = cv2.bitwise_or(skel1,temp)\n",
        "            img = eroded.copy()\n",
        "            if cv2.countNonZero(img)==0:\n",
        "                break\n",
        "\n",
        "        skel1 = np.array(skel1 * 255, dtype = np.uint8)\n",
        "        lines = cv2.HoughLines(skel1,1,np.pi/180,100)\n",
        "        if lines is None:#When no lines are found\n",
        "            lines=np.zeros((1,1,2))\n",
        "        tdeg = lines[:,:,1]*180/np.pi\n",
        "        clustering = DBSCAN(eps=self.eps1, min_samples=1).fit(tdeg)\n",
        "        clusters = defaultdict(list)\n",
        "        slines1 = []\n",
        "        for i,c in enumerate(clustering.labels_): # Sort Clusters into groups\n",
        "            clusters[c].append(tdeg[i])\n",
        "        for i,c in enumerate(clusters): # Select one candidate per cluster\n",
        "            k=(max(list(clusters[i]))[0])//90\n",
        "            slines1.append((k*max(list(clusters[i]))[0])+((1-k)*min(list(clusters[i]))[0]))#choose min if angle<90 or max if angle>90\n",
        "\n",
        "        while True:\n",
        "            openImg = cv2.morphologyEx(lbl, cv2.MORPH_OPEN, element)\n",
        "            temp = cv2.subtract(lbl, openImg)\n",
        "            eroded = cv2.erode(lbl, element)\n",
        "            skel2 = cv2.bitwise_or(skel2,temp)\n",
        "            lbl = eroded.copy()\n",
        "            if cv2.countNonZero(lbl)==0:\n",
        "                break\n",
        "\n",
        "        skel2 = np.array(skel2 * 255, dtype = np.uint8)\n",
        "        lines = cv2.HoughLines(skel2,1,np.pi/180,self.htres)\n",
        "        if lines is None:#When no lines are found\n",
        "            lines=np.zeros((1,1,2))\n",
        "        tdeg = lines[:,:,1]*180/np.pi\n",
        "        clustering = DBSCAN(eps=self.eps1, min_samples=1).fit(tdeg)\n",
        "        clusters = defaultdict(list)\n",
        "        slines2 = []\n",
        "        for i,c in enumerate(clustering.labels_): # Sort Clusters into groups\n",
        "            clusters[c].append(tdeg[i])\n",
        "        for i,c in enumerate(clusters): # Select one candidate per cluster\n",
        "            k=(max(list(clusters[i]))[0])//90\n",
        "            slines2.append((k*max(list(clusters[i]))[0])+((1-k)*min(list(clusters[i]))[0]))#choose min if angle<90 or max if angle>90\n",
        "\n",
        "        slines = slines1+slines2\n",
        "        slines = np.array(slines).reshape(-1,1)\n",
        "\n",
        "        clustering = DBSCAN(eps=self.eps2, min_samples=1).fit(slines)\n",
        "        clusters = defaultdict(list)\n",
        "\n",
        "        for i,c in enumerate(clustering.labels_): # Sort Clusters into groups\n",
        "            clusters[c].append(slines[i])\n",
        "\n",
        "        error = []\n",
        "        for i,c in enumerate(clusters): # Select one candidate per cluster\n",
        "            if (len(list(clusters[i]))) > 1:\n",
        "                error.append(max(clusters[i])-min(clusters[i]))\n",
        "\n",
        "        error = np.array(error)\n",
        "        e = (abs(error[error!=0].mean()))/10\n",
        "        if math.isnan(e):\n",
        "            e = 0.0\n",
        "        #e = tf.convert_to_tensor(e)\n",
        "        #y_p = K.print_tensor(e.type, message='etype = ')\n",
        "        return e\n",
        "\n",
        "    def get_unet(self):\n",
        "        inputs = Input((self.img_rows, self.img_cols, 3))\n",
        "\n",
        "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "        # print(conv1)\n",
        "        print (\"conv1 shape:\", conv1.shape)\n",
        "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "        print (\"conv1 shape:\", conv1.shape)\n",
        "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "        print (\"pool1 shape:\", pool1.shape)\n",
        "\n",
        "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "        print (\"conv2 shape:\", conv2.shape)\n",
        "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "        print (\"conv2 shape:\", conv2.shape)\n",
        "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "        print (\"pool2 shape:\", pool2.shape)\n",
        "\n",
        "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "        print (\"conv3 shape:\", conv3.shape)\n",
        "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "        print (\"conv3 shape:\", conv3.shape)\n",
        "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "        print (\"pool3 shape:\", pool3.shape)\n",
        "\n",
        "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "        drop4 = Dropout(0.5)(conv4)\n",
        "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "        drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "        up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "            UpSampling2D(size=(2, 2))(drop5))\n",
        "        merge6 = concatenate([drop4, up6],axis=3)\n",
        "        print(up6)\n",
        "        print(merge6)\n",
        "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "        print(conv6)\n",
        "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "        print(conv6)\n",
        "        up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "            UpSampling2D(size=(2, 2))(conv6))\n",
        "        merge7 = concatenate([conv3, up7],axis=3)\n",
        "        print(up7)\n",
        "        print(merge7)\n",
        "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "        print(conv7)\n",
        "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "        print(conv7)\n",
        "        up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "            UpSampling2D(size=(2, 2))(conv7))\n",
        "        merge8 = concatenate([conv2, up8],axis=3)\n",
        "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "        up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "            UpSampling2D(size=(2, 2))(conv8))\n",
        "        merge9 = concatenate([conv1, up9], axis=3)\n",
        "        print(up9)\n",
        "        print(merge9)\n",
        "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "        print(conv9)\n",
        "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "        print(conv9)\n",
        "        conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "        print (\"conv9 shape:\", conv9.shape)\n",
        "\n",
        "        conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "        print(conv10)\n",
        "        model = Model(inputs, conv10)\n",
        "\n",
        "        #weights = [1,2]\n",
        "        #model.compile(optimizer=Adam(lr=1e-4), loss= self.weightedLoss(tf.keras.losses.BinaryCrossentropy(from_logits=True), weights), metrics=['accuracy', self.iou, self.loss_angle], run_eagerly=True)\n",
        "        #model.compile(optimizer=Adam(lr=1e-4), loss=BinaryFocalLoss(gamma=2), metrics=['accuracy', self.iou, self.loss_angle], run_eagerly=True)\n",
        "        model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy', self.iou], run_eagerly=True)\n",
        "        #model.compile(optimizer=Adam(lr=1e-4), loss=self.loss_angle, metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        print(\"loading data\")\n",
        "        #\n",
        "        #\n",
        "        #\n",
        "        imgs_train, imgs_mask_train, imgs_test, imgs_mask_test, imgs_val, imgs_mask_val = self.load_data()\n",
        "        print(\"loading data done\")\n",
        "        model = self.get_unet()\n",
        "        print(\"got unet\")\n",
        "        #model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/unet-rgb/unet.hdf5', monitor='val_iou', mode='max', verbose=1, save_best_only=True)\n",
        "        model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/TeaBot Research Dataset/model/model.hdf5', monitor='iou', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "        print('Fitting model...')\n",
        "        #epochs=20\n",
        "        history = model.fit(imgs_train, imgs_mask_train, batch_size=1, epochs=5, verbose=1,\n",
        "                 validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
        "        #epochs=40\n",
        "        history = model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=10, verbose=1,\n",
        "                  validation_data=(imgs_val, imgs_mask_val), shuffle=True, callbacks=[model_checkpoint, tensorboard])\n",
        "\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        #\n",
        "\n",
        "        #plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train','validation'], loc='upper left')\n",
        "        plt.savefig('/content/drive/MyDrive/TeaBot Research Dataset/accuracy.png')\n",
        "        plt.close('all')\n",
        "\n",
        "        plt.plot(history.history['iou'])\n",
        "       # plt.plot(history.history['val_iou'])\n",
        "        #plt.title('model iou')\n",
        "        plt.ylabel('iou')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train','validation'], loc='upper left')\n",
        "        plt.savefig('/content/drive/MyDrive/TeaBot Research Dataset/iou.png')\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train','validation'], loc='upper left')\n",
        "        plt.savefig('/content/drive/MyDrive/TeaBot Research Dataset/loss.png')\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    myunet = myUnet()\n",
        "    model = myunet.get_unet()\n",
        "    model.summary()\n",
        "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    myunet.train()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}